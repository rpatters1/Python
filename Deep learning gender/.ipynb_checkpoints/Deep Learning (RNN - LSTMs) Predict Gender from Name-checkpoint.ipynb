{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Deep Learning gender from name - RNN LSTMs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will use an LSTM RNN to learn gender as f(name). we will use a stacked LSTM with many-to-one architecture feeding charecter inputs and predicting a binary outcome M/F. loss function used will be binary_crossentropy (a special case of categorical_crossentropy with m=2) and using adam optimizer (modified SGD) sample input /output would like this <br> ['r','a','k','e','s','h',' '] - male<br> ['p','r','a','d','e','e','p'] - male<br> ['g','a','n','g','a',' '] - female<br> and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LSTM_RNN_architecture.jpg\" width=\"800\" height=\"600\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "regexp applied\n",
    "[^a-zA-Z0-9 ,.\\r\\n] = remove\n",
    "[ ]+ = ' '\n",
    "[^a-zA-Z ,.\\r\\n] = remove\n",
    "[ ]{3}+ - regex to check where 3 consecutive space occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertpatterson/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "maxlen = 30\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.read_csv(\"gender_data.csv\",header=None)\n",
    "input.columns = ['name','m_or_f']\n",
    "input['namelen']= [len(str(i)) for i in input['name']]\n",
    "input1 = input[(input['namelen'] >= 2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_or_f\n",
       "f    6705\n",
       "m    8475\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.groupby('m_or_f')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = input['name']\n",
    "gender = input['m_or_f']\n",
    "vocab = set(' '.join([str(i) for i in names]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z', 'c', 'p', 'END', 'd', '3', 'i', 'o', '4', '.', 'w', 'n', '1', 'f', 'l', '0', 'a', 'v', 'e', '9', 't', 'y', 'r', 'g', ' ', 'b', 'u', 's', 'j', '8', 'q', 'm', 'x', '7', '2', 'k', '6', 'h', '5'}\n",
      "vocab length is  39\n",
      "length of input is  15226\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(\"vocab length is \",len_vocab)\n",
    "print (\"length of input is \",len(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_index = dict((c, i) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z': 0, 'c': 1, 'p': 2, 'END': 3, 'd': 4, '3': 5, 'i': 6, 'o': 7, '4': 8, '.': 9, 'w': 10, 'n': 11, '1': 12, 'f': 13, 'l': 14, '0': 15, 'a': 16, 'v': 17, 'e': 18, '9': 19, 't': 20, 'y': 21, 'r': 22, 'g': 23, ' ': 24, 'b': 25, 'u': 26, 's': 27, 'j': 28, '8': 29, 'q': 30, 'm': 31, 'x': 32, '7': 33, '2': 34, 'k': 35, '6': 36, 'h': 37, '5': 38}\n"
     ]
    }
   ],
   "source": [
    "print(char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "msk = np.random.rand(len(input1)) < 0.8\n",
    "train = input1[msk]\n",
    "test = input1[~msk]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "train_X = []\n",
    "trunc_train_name = [str(i)[0:30] for i in train.name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12223, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_flag(i):\n",
    "    tmp = np.zeros(39);\n",
    "    tmp[i] = 1\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_flag(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modify the code above to also convert each index to one-hot encoded representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "#also convert each index to one-hot encoding\n",
    "train_X = []\n",
    "train_Y = []\n",
    "trunc_train_name = [str(i)[0:maxlen] for i in train.name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    train_X.append(tmp)\n",
    "for i in train.m_or_f:\n",
    "    if i == 'm':\n",
    "        train_Y.append([1,0])\n",
    "    else:\n",
    "        train_Y.append([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12223, 30, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12223, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build model in keras ( a stacked LSTM model with many-to-one arch ) here 30 sequence and 2 output each for one category(m/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 512)           1130496   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,722\n",
      "Trainable params: 3,230,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the model: 2 stacked LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "trunc_test_name = [str(i)[0:maxlen] for i in test.name]\n",
    "for i in trunc_test_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    test_X.append(tmp)\n",
    "for i in test.m_or_f:\n",
    "    if i == 'm':\n",
    "        test_Y.append([1,0])\n",
    "    else:\n",
    "        test_Y.append([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3003, 30, 39)\n",
      "(3003, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(test_X).shape)\n",
    "print(np.asarray(test_Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1a1b63881f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(train_X, train_Y,batch_size=batch_size,epochs=10,validation_data=(np.asarray(test_X), np.asarray(test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028/3028 [==============================] - 16s    \n",
      "Test score: 0.453434576998\n",
      "Test accuracy: 0.789299867978\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_X, test_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[\"sandhya\",\"jaspreet\",\"rajesh\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62356585,  0.37643418],\n",
       "       [ 0.72094178,  0.27905828],\n",
       "       [ 0.90337974,  0.09662029]], dtype=float32)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train more, clearly some very simple female names it doesnt get right like mentioned above (inspite it exists in training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12198 samples, validate on 3028 samples\n",
      "Epoch 1/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.4107 - acc: 0.8137 - val_loss: 0.4408 - val_acc: 0.7966\n",
      "Epoch 2/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.3912 - acc: 0.8254 - val_loss: 0.4479 - val_acc: 0.7936\n",
      "Epoch 3/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3927 - acc: 0.8228 - val_loss: 0.4511 - val_acc: 0.7982\n",
      "Epoch 4/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3730 - acc: 0.8344 - val_loss: 0.4253 - val_acc: 0.8071\n",
      "Epoch 5/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3640 - acc: 0.8396 - val_loss: 0.4240 - val_acc: 0.8164\n",
      "Epoch 6/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3490 - acc: 0.8505 - val_loss: 0.4183 - val_acc: 0.8180\n",
      "Epoch 7/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3411 - acc: 0.8542 - val_loss: 0.4089 - val_acc: 0.8243\n",
      "Epoch 8/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3396 - acc: 0.8529 - val_loss: 0.4026 - val_acc: 0.8184\n",
      "Epoch 9/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.3294 - acc: 0.8590 - val_loss: 0.3781 - val_acc: 0.8451\n",
      "Epoch 10/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3159 - acc: 0.8684 - val_loss: 0.3935 - val_acc: 0.8332\n",
      "Epoch 11/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.3025 - acc: 0.8736 - val_loss: 0.3912 - val_acc: 0.8425\n",
      "Epoch 12/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2921 - acc: 0.8808 - val_loss: 0.3981 - val_acc: 0.8408\n",
      "Epoch 13/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2885 - acc: 0.8800 - val_loss: 0.4018 - val_acc: 0.8336\n",
      "Epoch 14/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2823 - acc: 0.8853 - val_loss: 0.3687 - val_acc: 0.8464\n",
      "Epoch 15/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2763 - acc: 0.8879 - val_loss: 0.3866 - val_acc: 0.8606\n",
      "Epoch 16/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2653 - acc: 0.8933 - val_loss: 0.3820 - val_acc: 0.8554\n",
      "Epoch 17/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2573 - acc: 0.8970 - val_loss: 0.3962 - val_acc: 0.8471\n",
      "Epoch 18/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2651 - acc: 0.8919 - val_loss: 0.3756 - val_acc: 0.8501\n",
      "Epoch 19/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2539 - acc: 0.8982 - val_loss: 0.3837 - val_acc: 0.8491\n",
      "Epoch 20/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2576 - acc: 0.8970 - val_loss: 0.4036 - val_acc: 0.8494\n",
      "Epoch 21/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.2476 - acc: 0.9010 - val_loss: 0.4013 - val_acc: 0.8471\n",
      "Epoch 22/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2485 - acc: 0.8985 - val_loss: 0.3795 - val_acc: 0.8587\n",
      "Epoch 23/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2273 - acc: 0.9087 - val_loss: 0.3745 - val_acc: 0.8583\n",
      "Epoch 24/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2287 - acc: 0.9074 - val_loss: 0.3830 - val_acc: 0.8570\n",
      "Epoch 25/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2205 - acc: 0.9097 - val_loss: 0.3870 - val_acc: 0.8563\n",
      "Epoch 26/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2133 - acc: 0.9150 - val_loss: 0.3778 - val_acc: 0.8656\n",
      "Epoch 27/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2024 - acc: 0.9225 - val_loss: 0.3910 - val_acc: 0.8646\n",
      "Epoch 28/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1911 - acc: 0.9244 - val_loss: 0.4067 - val_acc: 0.8570\n",
      "Epoch 29/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1869 - acc: 0.9241 - val_loss: 0.4113 - val_acc: 0.8633\n",
      "Epoch 30/50\n",
      "12198/12198 [==============================] - 147s - loss: 0.1897 - acc: 0.9229 - val_loss: 0.3766 - val_acc: 0.8662\n",
      "Epoch 31/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1786 - acc: 0.9279 - val_loss: 0.4527 - val_acc: 0.8623\n",
      "Epoch 32/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1728 - acc: 0.9311 - val_loss: 0.4064 - val_acc: 0.8633\n",
      "Epoch 33/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1893 - acc: 0.9250 - val_loss: 0.3870 - val_acc: 0.8613\n",
      "Epoch 34/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.1880 - acc: 0.9253 - val_loss: 0.3886 - val_acc: 0.8692\n",
      "Epoch 35/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1672 - acc: 0.9344 - val_loss: 0.4596 - val_acc: 0.8504\n",
      "Epoch 36/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1610 - acc: 0.9329 - val_loss: 0.4256 - val_acc: 0.8669\n",
      "Epoch 37/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1596 - acc: 0.9344 - val_loss: 0.4235 - val_acc: 0.8705\n",
      "Epoch 38/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1651 - acc: 0.9333 - val_loss: 0.4543 - val_acc: 0.8596\n",
      "Epoch 39/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1557 - acc: 0.9382 - val_loss: 0.4427 - val_acc: 0.8662\n",
      "Epoch 40/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1558 - acc: 0.9371 - val_loss: 0.4607 - val_acc: 0.8530\n",
      "Epoch 41/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1461 - acc: 0.9410 - val_loss: 0.4565 - val_acc: 0.8633\n",
      "Epoch 42/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1365 - acc: 0.9444 - val_loss: 0.4703 - val_acc: 0.8600\n",
      "Epoch 43/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1310 - acc: 0.9461 - val_loss: 0.5031 - val_acc: 0.8705\n",
      "Epoch 44/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1247 - acc: 0.9480 - val_loss: 0.4818 - val_acc: 0.8643\n",
      "Epoch 45/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1173 - acc: 0.9520 - val_loss: 0.5398 - val_acc: 0.8662\n",
      "Epoch 46/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.1194 - acc: 0.9508 - val_loss: 0.5055 - val_acc: 0.8649\n",
      "Epoch 47/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1230 - acc: 0.9512 - val_loss: 0.5328 - val_acc: 0.8656\n",
      "Epoch 48/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1219 - acc: 0.9491 - val_loss: 0.5247 - val_acc: 0.8696\n",
      "Epoch 49/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1245 - acc: 0.9492 - val_loss: 0.4557 - val_acc: 0.8676\n",
      "Epoch 50/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1437 - acc: 0.9427 - val_loss: 0.4484 - val_acc: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fe98ba8d0>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(train_X, train_Y,batch_size=batch_size,nb_epoch=50,validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028/3028 [==============================] - 16s    \n",
      "Test score: 0.448404541104\n",
      "Test accuracy: 0.864266842879\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_X, test_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> lets look at the loss and accuracy chart as a function of epochs </h3><img src=\"loss_charts.bmp\" alt=\"loss charts\" width=\"500\" height=\"350\"/><img src=\"acc_charts.bmp\" alt=\"loss charts\"  width=\"500\" height=\"350\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0859881 ,  0.91401184],\n",
       "       [ 0.96310365,  0.03689628],\n",
       "       [ 0.7148453 ,  0.28515476],\n",
       "       [ 0.02246205,  0.97753793],\n",
       "       [ 0.13607673,  0.86392319],\n",
       "       [ 0.99559009,  0.00440993],\n",
       "       [ 0.05380283,  0.94619709],\n",
       "       [ 0.55060732,  0.44939268],\n",
       "       [ 0.10676169,  0.89323831]], dtype=float32)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"sandhya\",\"jaspreet\",\"rajesh\",\"kaveri\",\"aditi deepak\",\"arihant\",\"sasikala\",\"aditi\",\"ragini rajaram\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15557961,  0.84442037],\n",
       "       [ 0.25342518,  0.74657482],\n",
       "       [ 0.8618474 ,  0.13815261]], dtype=float32)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"abhi\",\"abhi deepak\",\"mr. abhi\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33718896,  0.66281104],\n",
       "       [ 0.99896383,  0.00103616],\n",
       "       [ 0.99664474,  0.00335527]], dtype=float32)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"rajini\",\"rajinikanth\",\"mr. rajini\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save our model and data\n",
    "model.save_weights('gender_model',overwrite=True)\n",
    "train.to_csv(\"train_split.csv\")\n",
    "test.to_csv(\"test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.predict(test_X)\n",
    "prob_m = [i[0] for i in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(prob_m)\n",
    "out['name'] = test.name.reset_index()['name']\n",
    "out['m_or_f']=test.m_or_f.reset_index()['m_or_f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head(10)\n",
    "out.columns = ['prob_m','name','actual']\n",
    "out.head(10)\n",
    "out.to_csv(\"gender_pred_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
