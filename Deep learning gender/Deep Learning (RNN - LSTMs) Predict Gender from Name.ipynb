{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Deep Learning gender from name - RNN LSTMs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will use an LSTM RNN to learn gender as f(name). we will use a stacked LSTM with many-to-one architecture feeding charecter inputs and predicting a binary outcome M/F. loss function used will be binary_crossentropy (a special case of categorical_crossentropy with m=2) and using adam optimizer (modified SGD) sample input /output would like this <br> ['r','a','k','e','s','h',' '] - male<br> ['p','r','a','d','e','e','p'] - male<br> ['g','a','n','g','a',' '] - female<br> and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LSTM_RNN_architecture.jpg\" width=\"800\" height=\"600\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "regexp applied\n",
    "[^a-zA-Z0-9 ,.\\r\\n] = remove\n",
    "[ ]+ = ' '\n",
    "[^a-zA-Z ,.\\r\\n] = remove\n",
    "[ ]{3}+ - regex to check where 3 consecutive space occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertpatterson/.virtualenvs/keras_tf_py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "maxlen = 30\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.read_csv(\"gender_data.csv\",header=None)\n",
    "input.columns = ['name','m_or_f']\n",
    "input['namelen']= [len(str(i)) for i in input['name']]\n",
    "input1 = input[(input['namelen'] >= 2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_or_f\n",
       "f    6705\n",
       "m    8475\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.groupby('m_or_f')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = input['name']\n",
    "gender = input['m_or_f']\n",
    "vocab = set(' '.join([str(i) for i in names]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z', 'c', 'p', 'END', 'd', '3', 'i', 'o', '4', '.', 'w', 'n', '1', 'f', 'l', '0', 'a', 'v', 'e', '9', 't', 'y', 'r', 'g', ' ', 'b', 'u', 's', 'j', '8', 'q', 'm', 'x', '7', '2', 'k', '6', 'h', '5'}\n",
      "vocab length is  39\n",
      "length of input is  15226\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(\"vocab length is \",len_vocab)\n",
    "print (\"length of input is \",len(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_index = dict((c, i) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z': 0, 'c': 1, 'p': 2, 'END': 3, 'd': 4, '3': 5, 'i': 6, 'o': 7, '4': 8, '.': 9, 'w': 10, 'n': 11, '1': 12, 'f': 13, 'l': 14, '0': 15, 'a': 16, 'v': 17, 'e': 18, '9': 19, 't': 20, 'y': 21, 'r': 22, 'g': 23, ' ': 24, 'b': 25, 'u': 26, 's': 27, 'j': 28, '8': 29, 'q': 30, 'm': 31, 'x': 32, '7': 33, '2': 34, 'k': 35, '6': 36, 'h': 37, '5': 38}\n"
     ]
    }
   ],
   "source": [
    "print(char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "msk = np.random.rand(len(input1)) < 0.8\n",
    "train = input1[msk]\n",
    "test = input1[~msk]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "train_X = []\n",
    "trunc_train_name = [str(i)[0:30] for i in train.name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12223, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_flag(i):\n",
    "    tmp = np.zeros(39);\n",
    "    tmp[i] = 1\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_flag(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modify the code above to also convert each index to one-hot encoded representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "#also convert each index to one-hot encoding\n",
    "train_X = []\n",
    "train_Y = []\n",
    "trunc_train_name = [str(i)[0:maxlen] for i in train.name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    train_X.append(tmp)\n",
    "for i in train.m_or_f:\n",
    "    if i == 'm':\n",
    "        train_Y.append([1,0])\n",
    "    else:\n",
    "        train_Y.append([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12223, 30, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12223, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build model in keras ( a stacked LSTM model with many-to-one arch ) here 30 sequence and 2 output each for one category(m/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 512)           1130496   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,722\n",
      "Trainable params: 3,230,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the model: 2 stacked LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "trunc_test_name = [str(i)[0:maxlen] for i in test.name]\n",
    "for i in trunc_test_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    test_X.append(tmp)\n",
    "for i in test.m_or_f:\n",
    "    if i == 'm':\n",
    "        test_Y.append([1,0])\n",
    "    else:\n",
    "        test_Y.append([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3003, 30, 39)\n",
      "(3003, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(test_X).shape)\n",
    "print(np.asarray(test_Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12223 samples, validate on 3003 samples\n",
      "Epoch 1/10\n",
      "12223/12223 [==============================] - 74s 6ms/step - loss: 0.6938 - acc: 0.5502 - val_loss: 0.6858 - val_acc: 0.5564\n",
      "Epoch 2/10\n",
      "12223/12223 [==============================] - 71s 6ms/step - loss: 0.6750 - acc: 0.5742 - val_loss: 0.6436 - val_acc: 0.6277\n",
      "Epoch 3/10\n",
      "12223/12223 [==============================] - 72s 6ms/step - loss: 0.6110 - acc: 0.6698 - val_loss: 0.5854 - val_acc: 0.6996\n",
      "Epoch 4/10\n",
      "12223/12223 [==============================] - 71s 6ms/step - loss: 0.5726 - acc: 0.7031 - val_loss: 0.5499 - val_acc: 0.7299\n",
      "Epoch 5/10\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.5425 - acc: 0.7344 - val_loss: 0.5179 - val_acc: 0.7609\n",
      "Epoch 6/10\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.5082 - acc: 0.7528 - val_loss: 0.5047 - val_acc: 0.7609\n",
      "Epoch 7/10\n",
      "12223/12223 [==============================] - 67s 5ms/step - loss: 0.4977 - acc: 0.7646 - val_loss: 0.4968 - val_acc: 0.7666\n",
      "Epoch 8/10\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.4887 - acc: 0.7652 - val_loss: 0.4795 - val_acc: 0.7852\n",
      "Epoch 9/10\n",
      "12223/12223 [==============================] - 67s 5ms/step - loss: 0.4833 - acc: 0.7740 - val_loss: 0.4964 - val_acc: 0.7752\n",
      "Epoch 10/10\n",
      "12223/12223 [==============================] - 196s 16ms/step - loss: 0.4862 - acc: 0.7708 - val_loss: 0.4899 - val_acc: 0.7835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122709630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(np.asarray(train_X), np.asarray(train_Y),batch_size=batch_size,epochs=10,validation_data=(np.asarray(test_X), np.asarray(test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3003/3003 [==============================] - 9s 3ms/step\n",
      "Test score: 0.4898969696693884\n",
      "Test accuracy: 0.7835497834703901\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(np.asarray(test_X), np.asarray(test_Y))\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[\"sandhya\",\"jaspreet\",\"rajesh\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62659043, 0.37340954],\n",
       "       [0.5595104 , 0.4404896 ],\n",
       "       [0.7332715 , 0.26672855]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train more, clearly some very simple female names it doesnt get right like mentioned above (inspite it exists in training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12223 samples, validate on 3003 samples\n",
      "Epoch 1/50\n",
      "12223/12223 [==============================] - 71s 6ms/step - loss: 0.4775 - acc: 0.7747 - val_loss: 0.4700 - val_acc: 0.7902\n",
      "Epoch 2/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.4621 - acc: 0.7840 - val_loss: 0.4719 - val_acc: 0.7919\n",
      "Epoch 3/50\n",
      "12223/12223 [==============================] - 69s 6ms/step - loss: 0.4586 - acc: 0.7839 - val_loss: 0.4516 - val_acc: 0.7969\n",
      "Epoch 4/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.4482 - acc: 0.7948 - val_loss: 0.4519 - val_acc: 0.8045\n",
      "Epoch 5/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.4385 - acc: 0.8000 - val_loss: 0.4419 - val_acc: 0.7969\n",
      "Epoch 6/50\n",
      "12223/12223 [==============================] - 67s 5ms/step - loss: 0.4242 - acc: 0.8095 - val_loss: 0.4536 - val_acc: 0.7975\n",
      "Epoch 7/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.4171 - acc: 0.8133 - val_loss: 0.4331 - val_acc: 0.8069\n",
      "Epoch 8/50\n",
      "12223/12223 [==============================] - 69s 6ms/step - loss: 0.4073 - acc: 0.8188 - val_loss: 0.4129 - val_acc: 0.8172\n",
      "Epoch 9/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.3878 - acc: 0.8297 - val_loss: 0.3920 - val_acc: 0.8305\n",
      "Epoch 10/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.3654 - acc: 0.8422 - val_loss: 0.3695 - val_acc: 0.8395\n",
      "Epoch 11/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.3670 - acc: 0.8420 - val_loss: 0.4131 - val_acc: 0.8202\n",
      "Epoch 12/50\n",
      "12223/12223 [==============================] - 70s 6ms/step - loss: 0.3723 - acc: 0.8419 - val_loss: 0.3676 - val_acc: 0.8495\n",
      "Epoch 13/50\n",
      "12223/12223 [==============================] - 69s 6ms/step - loss: 0.3438 - acc: 0.8579 - val_loss: 0.3530 - val_acc: 0.8518\n",
      "Epoch 14/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.3260 - acc: 0.8650 - val_loss: 0.3410 - val_acc: 0.8641\n",
      "Epoch 15/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.3188 - acc: 0.8686 - val_loss: 0.3353 - val_acc: 0.8578\n",
      "Epoch 16/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.3121 - acc: 0.8725 - val_loss: 0.3370 - val_acc: 0.8625\n",
      "Epoch 17/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.3074 - acc: 0.8752 - val_loss: 0.3419 - val_acc: 0.8605\n",
      "Epoch 18/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.3128 - acc: 0.8705 - val_loss: 0.3315 - val_acc: 0.8655\n",
      "Epoch 19/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2937 - acc: 0.8827 - val_loss: 0.3314 - val_acc: 0.8668\n",
      "Epoch 20/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2916 - acc: 0.8806 - val_loss: 0.3442 - val_acc: 0.8635\n",
      "Epoch 21/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2924 - acc: 0.8818 - val_loss: 0.3313 - val_acc: 0.8661\n",
      "Epoch 22/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2878 - acc: 0.8849 - val_loss: 0.3214 - val_acc: 0.8738\n",
      "Epoch 23/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2869 - acc: 0.8873 - val_loss: 0.3417 - val_acc: 0.8675\n",
      "Epoch 24/50\n",
      "12223/12223 [==============================] - 67s 5ms/step - loss: 0.2814 - acc: 0.8863 - val_loss: 0.3155 - val_acc: 0.8761\n",
      "Epoch 25/50\n",
      "12223/12223 [==============================] - 67s 5ms/step - loss: 0.2698 - acc: 0.8933 - val_loss: 0.3220 - val_acc: 0.8698\n",
      "Epoch 26/50\n",
      "12223/12223 [==============================] - 67s 5ms/step - loss: 0.2689 - acc: 0.8941 - val_loss: 0.3267 - val_acc: 0.8701\n",
      "Epoch 27/50\n",
      "12223/12223 [==============================] - 126s 10ms/step - loss: 0.2683 - acc: 0.8941 - val_loss: 0.3253 - val_acc: 0.8691\n",
      "Epoch 28/50\n",
      "12223/12223 [==============================] - 76s 6ms/step - loss: 0.2637 - acc: 0.8936 - val_loss: 0.3203 - val_acc: 0.8698\n",
      "Epoch 29/50\n",
      "12223/12223 [==============================] - 75s 6ms/step - loss: 0.2567 - acc: 0.9003 - val_loss: 0.3229 - val_acc: 0.8745\n",
      "Epoch 30/50\n",
      "12223/12223 [==============================] - 75s 6ms/step - loss: 0.2550 - acc: 0.9003 - val_loss: 0.3060 - val_acc: 0.8765\n",
      "Epoch 31/50\n",
      "12223/12223 [==============================] - 75s 6ms/step - loss: 0.2456 - acc: 0.9047 - val_loss: 0.3229 - val_acc: 0.8765\n",
      "Epoch 32/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.2393 - acc: 0.9073 - val_loss: 0.3087 - val_acc: 0.8808\n",
      "Epoch 33/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.2381 - acc: 0.9082 - val_loss: 0.3271 - val_acc: 0.8681\n",
      "Epoch 34/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.2417 - acc: 0.9040 - val_loss: 0.3087 - val_acc: 0.8771\n",
      "Epoch 35/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2277 - acc: 0.9125 - val_loss: 0.3198 - val_acc: 0.8781\n",
      "Epoch 36/50\n",
      "12223/12223 [==============================] - 67s 6ms/step - loss: 0.2247 - acc: 0.9145 - val_loss: 0.3204 - val_acc: 0.8861\n",
      "Epoch 37/50\n",
      "12223/12223 [==============================] - 68s 6ms/step - loss: 0.2254 - acc: 0.9148 - val_loss: 0.3172 - val_acc: 0.8731\n",
      "Epoch 38/50\n",
      "12223/12223 [==============================] - 688s 56ms/step - loss: 0.2263 - acc: 0.9139 - val_loss: 0.3007 - val_acc: 0.8831\n",
      "Epoch 39/50\n",
      "12223/12223 [==============================] - 76s 6ms/step - loss: 0.2224 - acc: 0.9143 - val_loss: 0.3290 - val_acc: 0.8771\n",
      "Epoch 40/50\n",
      "12223/12223 [==============================] - 75s 6ms/step - loss: 0.2126 - acc: 0.9188 - val_loss: 0.3227 - val_acc: 0.8838\n",
      "Epoch 41/50\n",
      "11000/12223 [=========================>....] - ETA: 6s - loss: 0.2216 - acc: 0.9157 "
     ]
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(np.asarray(train_X), np.asarray(train_Y),batch_size=batch_size,epochs=50,validation_data=(np.asarray(test_X), np.asarray(test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028/3028 [==============================] - 16s    \n",
      "Test score: 0.448404541104\n",
      "Test accuracy: 0.864266842879\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_X, test_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> lets look at the loss and accuracy chart as a function of epochs </h3><img src=\"loss_charts.bmp\" alt=\"loss charts\" width=\"500\" height=\"350\"/><img src=\"acc_charts.bmp\" alt=\"loss charts\"  width=\"500\" height=\"350\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0859881 ,  0.91401184],\n",
       "       [ 0.96310365,  0.03689628],\n",
       "       [ 0.7148453 ,  0.28515476],\n",
       "       [ 0.02246205,  0.97753793],\n",
       "       [ 0.13607673,  0.86392319],\n",
       "       [ 0.99559009,  0.00440993],\n",
       "       [ 0.05380283,  0.94619709],\n",
       "       [ 0.55060732,  0.44939268],\n",
       "       [ 0.10676169,  0.89323831]], dtype=float32)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"sandhya\",\"jaspreet\",\"rajesh\",\"kaveri\",\"aditi deepak\",\"arihant\",\"sasikala\",\"aditi\",\"ragini rajaram\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15557961,  0.84442037],\n",
       "       [ 0.25342518,  0.74657482],\n",
       "       [ 0.8618474 ,  0.13815261]], dtype=float32)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"abhi\",\"abhi deepak\",\"mr. abhi\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33718896,  0.66281104],\n",
       "       [ 0.99896383,  0.00103616],\n",
       "       [ 0.99664474,  0.00335527]], dtype=float32)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"rajini\",\"rajinikanth\",\"mr. rajini\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save our model and data\n",
    "model.save_weights('gender_model',overwrite=True)\n",
    "train.to_csv(\"train_split.csv\")\n",
    "test.to_csv(\"test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.predict(test_X)\n",
    "prob_m = [i[0] for i in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(prob_m)\n",
    "out['name'] = test.name.reset_index()['name']\n",
    "out['m_or_f']=test.m_or_f.reset_index()['m_or_f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head(10)\n",
    "out.columns = ['prob_m','name','actual']\n",
    "out.head(10)\n",
    "out.to_csv(\"gender_pred_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
